{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# cd drive/MyDrive/ECS271_project/house-price-prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *\n",
    "from networks import *\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some tunable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "lr = 0.001\n",
    "mom = 0.5\n",
    "epochs = 50\n",
    "networ_type = 'CNN' #FNN CNN\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(\"train.csv\", 0, 0.7)\n",
    "test = MyDataset(\"train.csv\", 0.7, 1)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = train.x.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=85264, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = eval(networ_type)()\n",
    "net.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/205 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646703877/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 205/205 [00:10<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.48864296078682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [00:06<00:00, 33.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.26303192973137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [00:06<00:00, 33.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.67878220416605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 160/205 [00:04<00:01, 33.53it/s]"
     ]
    }
   ],
   "source": [
    "los = []\n",
    "tlos = []\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0.0\n",
    "    net.train()\n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_loader), 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # Move to GPU / CPU\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "\n",
    "        labels = labels.unsqueeze(-1).unsqueeze(-1)\n",
    "        # forward + backward + optimize\n",
    "        l = [m.outer(m) for m in inputs]\n",
    "        inputs = torch.empty((len(l),)+l[0].shape, dtype=torch.float32, device=device)\n",
    "        for j in range(len(l)):\n",
    "            inputs[j] = l[j]\n",
    "        # for inp in inputs:\n",
    "        # inputs = inputs.outer(inputs)  #np.array([np.diag(i) for i in inputs])\n",
    "        inputs = inputs.unsqueeze(1) #.to_sparse()\n",
    "        # print(inputs.shape)\n",
    "        outputs = net(inputs).unsqueeze(-1)\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        tot_loss += loss.item()\n",
    "    print(tot_loss)\n",
    "    # ttot_loss = 0.0\n",
    "    # net.eval()\n",
    "    # for i, (inputs, labels) in enumerate(test_loader, 0):\n",
    "    #     # inputs, labels = inputs.to(device), labels.to(device) # Move to GPU / CPU\n",
    "    #     with torch.no_grad():\n",
    "    #         labels = labels.reshape((-1, 1))\n",
    "    #         inputs = torch.Tensor(inputs).unsqueeze(1) #.to_sparse()\n",
    "    #         outputs = net(inputs)\n",
    "    #         loss = criterion(outputs, labels)\n",
    "    #     ttot_loss += loss.item()\n",
    "    los.append(tot_loss)\n",
    "    # tlos.append(ttot_loss)\n",
    "    # print(tot_loss, ttot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(los, label=\"train\")\n",
    "plt.plot(tlos, label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "all_loss_train = []\n",
    "with torch.no_grad():\n",
    "    tot_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_loader), 0):\n",
    "        l = [m.outer(m) for m in inputs]\n",
    "        inputs = torch.empty((batch_size,)+l[0].shape, dtype=torch.float32)\n",
    "        for j in range(len(l)):\n",
    "            inputs[j] = l[j]\n",
    "        inputs = torch.Tensor(inputs).unsqueeze(1) #.to_sparse()\n",
    "        # inputs = torch.Tensor(inputs).unsqueeze(1) #.to_sparse()\n",
    "        outputs = net(inputs).ravel()\n",
    "        all_loss_train.extend((abs(outputs - labels) / abs(labels)).tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.x.shape)\n",
    "print(test.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "439%5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss_test = []\n",
    "with torch.no_grad():\n",
    "    tot_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(tqdm(test_loader), 0):\n",
    "        # labels = labels.reshape((-1, 1))\n",
    "        # inputs = torch.Tensor(inputs).unsqueeze(1) #.to_sparse()\n",
    "        l = [m.outer(m) for m in inputs]\n",
    "        size = len(l)\n",
    "        inputs = torch.empty((size,)+l[0].shape, dtype=torch.float32)\n",
    "        print(inputs.shape, labels.shape)\n",
    "        for j in range(len(l)):\n",
    "            inputs[j] = l[j]\n",
    "        inputs = torch.Tensor(inputs).unsqueeze(1)\n",
    "        outputs = net(inputs).ravel()\n",
    "        # if outputs.shape != labels.shape:\n",
    "        #     print(outputs)\n",
    "        #     print(labels)\n",
    "        all_loss_test.extend((abs(outputs - labels) / abs(labels)).tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss_train = np.array(all_loss_train)\n",
    "all_loss_test = np.array(all_loss_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(all_loss_train < 1)[0]) / len(all_loss_train), len(np.where(all_loss_test < 1)[0]) / len(all_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_pred_train = all_loss_train[np.where(all_loss_train < 1)]\n",
    "good_pred_test = all_loss_test[np.where(all_loss_test < 1)]\n",
    "good_pred_train.mean(), good_pred_train.std(), good_pred_test.mean(), good_pred_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(good_pred_train*100, bins=100, label=\"train\")\n",
    "plt.hist(good_pred_test*100, bins=100, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_loss = np.array(all_loss) * train.y_std + train.y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
